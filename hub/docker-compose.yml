services:
  domino-hub:
    build: .
    container_name: domino-hub
    ports:
      - "2424:2424"
    env_file:
      - .env
    environment:
      - MEMORY_DB_PATH=/data/memory.db
    restart: unless-stopped
    volumes:
      - /opt/domino_hub/data:/data
    networks:
      - proxy       # for Traefik / external access
      - ai          # internal AI backbone (Fish, Whisper, etc.)
    labels:
      - "traefik.enable=true"
      - "traefik.docker.network=proxy"
      - "traefik.http.routers.chat.entrypoints=https"
      - "traefik.http.routers.chat.rule=Host(`chat.lyfesaver.net`)"
      - "traefik.http.routers.chat.tls=true"
      - "traefik.http.routers.chat.tls.certresolver=cloudflare"
      - "traefik.http.routers.chat.service=chat"
      - "traefik.http.services.chat.loadbalancer.server.port=2424"

  whisper:
    build: ../services/whisper-service
    container_name: whisper-service
    restart: unless-stopped
    networks:
      - ai
    ports:
      - "9000:9000"
    environment:
      - WHISPER_MODEL=base.en
      - WHISPER_DEVICE=cuda
      - WHISPER_COMPUTE_TYPE=float16
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    gpus: all
    volumes:
      - whisper_cache:/root/.cache     # cache models between restarts

  fish-speech-server:
    build:
      context: ../services/tts-fish/fish-speech
      dockerfile: docker/Dockerfile
      target: server
      args:
        BACKEND: cuda
        CUDA_VER: 12.8.0
        UV_EXTRA: cu128
    container_name: fish-speech-server
    restart: unless-stopped
    networks:
      - ai
    # Optional: keep host port for debugging / direct hits
    ports:
      - "18080:8080"
    environment:
      - COMPILE=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Optional: needed only if you want to download gated models from Hugging Face.
      # (Set this in your project .env or host env; do not commit the token.)
      - HUGGINGFACE_HUB_TOKEN
    gpus: all
    volumes:
      # Checkpoints are required by the Fish image.
      # Ensure /opt/fish_tts/checkpoints contains the model files (or run the
      # container's /app/tools/download_models.py once to populate it).
      - /opt/tts-fish/checkpoints:/app/checkpoints
      - /opt/tts-fish/references:/app/references

  fish-ui:
    image: nginx:alpine
    container_name: fish-ui
    restart: unless-stopped
    networks:
      - ai
    ports:
      - "18081:80"
    volumes:
      # UI assets are mounted from the host. Override DOMINO_UI_DIR for non-/opt installs.
      # Example (local dev): DOMINO_UI_DIR=./ui
      - ${DOMINO_UI_DIR:-/opt/domino_hub/ui}:/usr/share/nginx/html:ro
      - ${DOMINO_UI_DIR:-/opt/domino_hub/ui}/nginx.conf:/etc/nginx/conf.d/default.conf:ro

    depends_on:
      - fish-speech-server

volumes:
  whisper_cache:
    driver: local

networks:
  proxy:
    external: true
  ai:
    driver: bridge
